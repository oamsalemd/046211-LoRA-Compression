{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import math\n",
    "#import optuna\n",
    "#import detectors\n",
    "#import timm\n",
    "from torchvision import transforms\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA H100 PCIe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the names all available GPU devices:\n",
    "[torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:04<00:00, 40046252.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Get the CIFAR10 dataset from 'torch':\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Download the training data from open datasets.\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# Create data loaders:\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m timm\u001b[39m.\u001b[39mcreate_model(\u001b[39m\"\u001b[39m\u001b[39mresnet18_cifar10\u001b[39m\u001b[39m\"\u001b[39m, pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timm' is not defined"
     ]
    }
   ],
   "source": [
    "model = timm.create_model(\"resnet18_cifar10\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the model's accuracy on the test data:\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# CIFAR10 mean and standard deviation:\n",
    "mean = [       0.4914,      0.4822,      0.4465    ]\n",
    "std = [      0.2023,      0.1994,      0.201 ]\n",
    "#mean = [       0.5,      0.5,      0.5    ]\n",
    "#std = [      0.5,      0.5,      0.5 ]\n",
    "\n",
    "normalize = transforms.Normalize(mean, std)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        images, labels = data\n",
    "        # Normalize the images batch:\n",
    "        images = normalize(images)\n",
    "        outputs = model(images)\n",
    "        predicted = outputs.argmax(dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if i % 10 == 0:\n",
    "            print(f'For step {i} the accuracy is {100 * correct / total}%')\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def quant_tensor(tensor):\n",
    "    quant_model_flatten = tensor\n",
    "    if tensor.numel() >= 16:\n",
    "        quant_model_flatten = quant_model_flatten.flatten()\n",
    "        quant_model_flatten = quant_model_flatten.unfold(0, 16, 16).mean(-1)\n",
    "        quant_model_flatten = quant_model_flatten.repeat_interleave(16)\n",
    "        quant_model_flatten = quant_model_flatten.view(10, 512)\n",
    "\n",
    "    return quant_model_flatten\n",
    "\n",
    "def quantize_linear_layers(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            # Extract weights and biases\n",
    "            weight = module.weight\n",
    "            bias = module.bias\n",
    "\n",
    "            # Quantize weights\n",
    "            quantized_weight = quant_tensor(weight)\n",
    "\n",
    "            # Replace original weights with quantized weights\n",
    "            module.weight = nn.Parameter(quantized_weight, requires_grad=False)\n",
    "\n",
    "            # Optional: Quantize biases if they exist\n",
    "            if bias is not None:\n",
    "                quantized_bias = quant_tensor(bias)\n",
    "                module.bias = nn.Parameter(quantized_bias, requires_grad=False)\n",
    "    return model\n",
    "\n",
    "quant_model = quantize_linear_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the model's accuracy on the test data:\n",
    "quant_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# CIFAR10 mean and standard deviation:\n",
    "mean = [       0.4914,      0.4822,      0.4465    ]\n",
    "std = [      0.2023,      0.1994,      0.201 ]\n",
    "#mean = [       0.5,      0.5,      0.5    ]\n",
    "#std = [      0.5,      0.5,      0.5 ]\n",
    "\n",
    "normalize = transforms.Normalize(mean, std)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        images, labels = data\n",
    "        # Normalize the images batch:\n",
    "        images = normalize(images)\n",
    "        outputs = quant_model(images)\n",
    "        predicted = outputs.argmax(dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if i % 10 == 0:\n",
    "            print(f'For step {i} the accuracy is {100 * correct / total}%')\n",
    "\n",
    "print(f'Accuracy of the quantized network on the 10000 test images: {100 * correct / total}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LoRA implementation and tests over MLP module and VGG pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vgg16_model = torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        std_dev = 1 / torch.sqrt(torch.tensor(rank).float())\n",
    "        self.A = nn.Parameter(torch.randn(in_dim, rank) * std_dev)\n",
    "        self.B = nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x\n",
    "\n",
    "class LinearWithLoRA(nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)\n",
    "\n",
    "def ReplaceLinearToLoRA(model, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            setattr(model, name, LinearWithLoRA(module, rank=rank, alpha=alpha))\n",
    "        else:\n",
    "            ReplaceLinearToLoRA(module, rank=rank, alpha=alpha)\n",
    "\n",
    "def FreeazeModel(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "def UnfreezeLoRA(model):\n",
    "    for child in model.children():\n",
    "        if isinstance(child, LoRALayer):\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            # Recursively freeze linear layers in children modules\n",
    "            UnfreezeLoRA(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1000, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self, num_features, \n",
    "        num_hidden_1, num_hidden_2, num_classes):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(num_features, num_hidden_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden_1, num_hidden_2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(num_hidden_2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MultilayerPerceptron(\n",
    "    num_features=100,\n",
    "    num_hidden_1=1000,\n",
    "    num_hidden_2=1000, \n",
    "    num_classes=10\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): LinearWithLoRA(\n",
      "      (linear): Linear(in_features=100, out_features=1000, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): LinearWithLoRA(\n",
      "      (linear): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (3): ReLU()\n",
      "    (4): LinearWithLoRA(\n",
      "      (linear): Linear(in_features=1000, out_features=10, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ReplaceLinearToLoRA(model, 4, 8)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FreeazeModel(model)\n",
    "UnfreezeLoRA(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vgg16_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReplaceLinearToLoRA(vgg16_model, 4, 8)\n",
    "print(vgg16_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FreeazeModel(vgg16_model)\n",
    "UnfreezeLoRA(vgg16_model)\n",
    "for name, param in vgg16_model.named_parameters():\n",
    "    print(f\"{name}: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
